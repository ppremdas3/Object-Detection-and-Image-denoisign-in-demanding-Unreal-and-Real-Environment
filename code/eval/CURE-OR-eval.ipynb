{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c514acf-f89d-40ea-8a72-d30c42b1c9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Pranav\\dip\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import maxim_pred as maxim\n",
    "import IAGC\n",
    "import cv2\n",
    "import numpy as np\n",
    "import eval_metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import matlab.engine\n",
    "import random\n",
    "from medpy.filter.smoothing import anisotropic_diffusion\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3335666-3804-4d62-8bd2-61c5beedd94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_eval_metrics(clean_data, noisy_data, agc_corrected_data, max_corrected_data, ad_corrected_data):\n",
    "    pre_psnr = []\n",
    "    post_psnr = []\n",
    "    pre_ssim = []\n",
    "    post_ssim = []\n",
    "    pre_cwssim = []\n",
    "    post_cwssim = []\n",
    "    pre_unique = []\n",
    "    post_unique = []\n",
    "    pre_msunique = []\n",
    "    post_msunique = []\n",
    "    pre_summer = []\n",
    "    post_summer = []\n",
    "    pre_csv = []\n",
    "    post_csv = []\n",
    "\n",
    "    post_psnr1 = []\n",
    "    post_ssim1 = []\n",
    "    post_cwssim1 = []\n",
    "    post_unique1 = []\n",
    "    post_msunique1 = []\n",
    "    post_summer1 = []\n",
    "    post_csv1 = []\n",
    "\n",
    "    post_psnr2 = []\n",
    "    post_ssim2 = []\n",
    "    post_cwssim2 = []\n",
    "    post_unique2 = []\n",
    "    post_msunique2 = []\n",
    "    post_summer2 = []\n",
    "    post_csv2 = []\n",
    "\n",
    "\n",
    "    print('Calculating evaluation metrics ...')\n",
    "    for i in tqdm(range(len(clean_data)), desc='processing'):\n",
    "        cimg = clean_data[i]\n",
    "        nimg = noisy_data[i]\n",
    "        y_agc = agc_corrected_data[i]\n",
    "        y_max = max_corrected_data[i]\n",
    "        y_ad = ad_corrected_data[i]\n",
    "    \n",
    "\n",
    "        m_cimg = matlab.double(cimg.tolist())\n",
    "        m_nimg = matlab.double(nimg.tolist())\n",
    "        m_y_agc = matlab.double(y_agc.tolist())\n",
    "        m_y_max = matlab.double(y_max.tolist())\n",
    "        m_y_ad = matlab.double(y_ad.tolist())\n",
    "\n",
    "        # Convert BGR to RGB\n",
    "        cimg = cv2.cvtColor(cimg, cv2.COLOR_BGR2RGB)\n",
    "        nimg = cv2.cvtColor(nimg, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        \n",
    "        pre_psnr.append(eval_metrics.PSNR(cimg, nimg))\n",
    "        pre_ssim.append(eval_metrics.calculate_ssim(cimg, nimg))\n",
    "        pre_cwssim.append(eval_metrics.calculate_cwssim(cimg, nimg))\n",
    "        pre_summer.append(eval_metrics.calculate_summer(cimg, nimg))\n",
    "        unique_val = eng.mslUNIQUE(m_cimg, m_nimg)\n",
    "        pre_unique.append(np.array(unique_val))\n",
    "        msunique_val = eng.mslMSUNIQUE(m_cimg, m_nimg)\n",
    "        pre_msunique.append(np.array(msunique_val))\n",
    "        csv_val = eng.csv(m_cimg, m_nimg)\n",
    "        pre_csv.append(np.array(csv_val))\n",
    "\n",
    "        post_psnr.append(eval_metrics.PSNR(cimg, y_agc))\n",
    "        post_ssim.append(eval_metrics.calculate_ssim(cimg, y_agc))\n",
    "        post_cwssim.append(eval_metrics.calculate_cwssim(cimg, y_agc))\n",
    "        post_summer.append(eval_metrics.calculate_summer(cimg, y_agc))\n",
    "        unique_val = eng.mslUNIQUE(m_cimg, m_y_agc)\n",
    "        post_unique.append(np.array(unique_val))\n",
    "        msunique_val = eng.mslMSUNIQUE(m_cimg, m_y_agc)\n",
    "        post_msunique.append(np.array(msunique_val))\n",
    "        csv_val = eng.csv(m_cimg, m_y_agc)\n",
    "        post_csv.append(np.array(csv_val))\n",
    "\n",
    "        post_psnr1.append(eval_metrics.PSNR(cimg, y_max))\n",
    "        post_ssim1.append(eval_metrics.calculate_ssim(cimg, y_max))\n",
    "        post_cwssim1.append(eval_metrics.calculate_cwssim(cimg, y_max))\n",
    "        post_summer1.append(eval_metrics.calculate_summer(cimg, y_max))\n",
    "        unique_val = eng.mslUNIQUE(m_cimg, m_y_max)\n",
    "        post_unique1.append(np.array(unique_val))\n",
    "        msunique_val = eng.mslMSUNIQUE(m_cimg, m_y_max)\n",
    "        post_msunique1.append(np.array(msunique_val))\n",
    "        csv_val = eng.csv(m_cimg, m_y_max)\n",
    "        post_csv1.append(np.array(csv_val))\n",
    "\n",
    "        post_psnr2.append(eval_metrics.PSNR(cimg, y_ad))\n",
    "        post_ssim2.append(eval_metrics.calculate_ssim(cimg, y_ad))\n",
    "        post_cwssim2.append(eval_metrics.calculate_cwssim(cimg, y_ad))\n",
    "        post_summer2.append(eval_metrics.calculate_summer(cimg, y_ad))\n",
    "        unique_val = eng.mslUNIQUE(m_cimg, m_y_ad)\n",
    "        post_unique2.append(np.array(unique_val))\n",
    "        msunique_val = eng.mslMSUNIQUE(m_cimg, m_y_ad)\n",
    "        post_msunique2.append(np.array(msunique_val))\n",
    "        csv_val = eng.csv(m_cimg, m_y_ad)\n",
    "        post_csv2.append(np.array(csv_val))\n",
    "\n",
    "    metrics = ['PSNR', 'SSIM', 'CWSSIM', 'UNIQUE', 'MSUNIQUE', 'SUMMER', 'CSV']\n",
    "    mean_values_initial = []\n",
    "    for i, lst in enumerate([pre_psnr, pre_ssim, pre_cwssim, pre_unique, pre_msunique, pre_summer, pre_csv]):\n",
    "        mean_value = np.mean(lst)\n",
    "        mean_values_initial.append([f\"{mean_value:.3f}\"])\n",
    "\n",
    "    # Display the mean values after adding 10 to the first element\n",
    "    mean_values_after_agc = []\n",
    "    for i, lst in enumerate([post_psnr, post_ssim, post_cwssim, post_unique, post_msunique, post_summer, post_csv]):\n",
    "        mean_value = np.mean(lst)\n",
    "        mean_values_after_agc.append([f\"{mean_value:.3f}\"])\n",
    "\n",
    "    # Display the mean values after adding 10 to the first element\n",
    "    mean_values_after_max = []\n",
    "    for i, lst in enumerate([post_psnr1, post_ssim1, post_cwssim1, post_unique1, post_msunique1, post_summer1, post_csv1]):\n",
    "        mean_value = np.mean(lst)\n",
    "        mean_values_after_max.append([f\"{mean_value:.3f}\"])\n",
    "\n",
    "    # Display the mean values after adding 10 to the first element\n",
    "    mean_values_after_ad = []\n",
    "    for i, lst in enumerate([post_psnr2, post_ssim2, post_cwssim2, post_unique2, post_msunique2, post_summer2, post_csv2]):\n",
    "        mean_value = np.mean(lst)\n",
    "        mean_values_after_ad.append([f\"{mean_value:.3f}\"])\n",
    "\n",
    "    return metrics, mean_values_initial, mean_values_after_agc, mean_values_after_max, mean_values_after_ad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7113534f-84fe-4ff9-8152-bf1ab8952372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading clean data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 29.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# cure-OR evaluation\n",
    "SIZE = 256\n",
    "path = 'D:/Pranav/Data/CURE-OR/input/challenge-free'\n",
    "clean_files = sorted([f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and not f.startswith('.')])\n",
    "idx = random.sample(range(len(clean_files)), 10)\n",
    "selected_clean_files = [clean_files[i] for i in idx]\n",
    "clean_data = []\n",
    "print('Loading clean data ...')\n",
    "for i in tqdm(selected_clean_files):\n",
    "    img = cv2.imread(path + '/' + i, 1)  # Change 0 to 1 for color images\n",
    "    img = cv2.resize(img, (SIZE, SIZE))\n",
    "    clean_data.append(np.array(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52c6ef23-aef0-42db-87c8-089d4739f9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['underexposure-level1', 'underexposure-level2', 'underexposure-level3', 'underexposure-level4', 'overexposure-level1', 'overexposure-level2', 'overexposure-level3', 'overexposure-level4', 'blur-level1', 'blur-level2', 'blur-level3', 'blur-level4', 'contrast-level1', 'contrast-level2', 'contrast-level3', 'contrast-level4', 'dirtylens-1-level1', 'dirtylens-1-level2', 'dirtylens-1-level3', 'dirtylens-1-level4', 'dirtylens-2-level1', 'dirtylens-2-level2', 'dirtylens-2-level3', 'dirtylens-2-level4', 'salt&pepper-level1', 'salt&pepper-level2', 'salt&pepper-level3', 'salt&pepper-level4', 'resize-level1', 'resize-level2', 'resize-level3', 'resize-level4']\n"
     ]
    }
   ],
   "source": [
    "directory_path = 'D:/Pranav/Data/CURE-OR/input/'\n",
    "# Get a list of folder names in the directory\n",
    "noise_types = [folder for folder in os.listdir(directory_path) if os.path.isdir(os.path.join(directory_path, folder))]\n",
    "noise_types.remove('challenge-free')\n",
    "eng = matlab.engine.start_matlab()\n",
    "print(noise_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "612b3463-c3cb-49dc-9687-4b7bce8888f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Pranav\\dip\\Lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:107: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Pranav\\dip\\Lib\\site-packages\\keras\\src\\engine\\functional.py:156: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Pranav\\dip\\Lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:178: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Pranav\\dip\\Lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:178: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "enhancement_model = tf.keras.models.load_model('D:/Pranav/Code/maxim-tf-main/models/Enhancement')\n",
    "deblurring_model = tf.keras.models.load_model('D:/Pranav/Code/maxim-tf-main/models/Deblurring')\n",
    "deraining_model = tf.keras.models.load_model('D:/Pranav/Code/maxim-tf-main/models/Deraining')\n",
    "dehazing_model = tf.keras.models.load_model('D:/Pranav/Code/maxim-tf-main/models/Dehazing')\n",
    "denoising_model = tf.keras.models.load_model('D:/Pranav/Code/maxim-tf-main/models/Denoising')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4959371a-e691-47a2-a2f4-9fcf30dc9937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_agc = pd.DataFrame(columns=['Noise Type', 'PSNR', 'SSIM', 'CW-SSIM', 'UNIQUE', 'MSUNIQUE', 'SUMMER', 'CSV'])\n",
    "df_max = pd.DataFrame(columns=['Noise Type', 'PSNR', 'SSIM', 'CW-SSIM', 'UNIQUE', 'MSUNIQUE', 'SUMMER', 'CSV'])\n",
    "df_ad = pd.DataFrame(columns=['Noise Type', 'PSNR', 'SSIM', 'CW-SSIM', 'UNIQUE', 'MSUNIQUE', 'SUMMER', 'CSV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0810164-24bb-4ae6-9ffa-0ad744deaa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as io\n",
    "import skimage.filters as flt\n",
    "%matplotlib inline\n",
    "# since we can't use imports\n",
    "import numpy as np\n",
    "import scipy.ndimage.filters as flt\n",
    "import warnings\n",
    "\n",
    "def anisodiff(img,niter=1,kappa=50,gamma=0.1,step=(1.,1.),sigma=0, option=1,ploton=False):\n",
    "\t# really want\n",
    "\tif img.ndim == 3:\n",
    "\t\twarnings.warn(\"Only grayscale images allowed, converting to 2D matrix\")\n",
    "\t\timg = img.mean(2)\n",
    "\n",
    "\t# initialize output array\n",
    "\timg = img.astype('float32')\n",
    "\timgout = img.copy()\n",
    "\n",
    "\t# initialize some internal variables\n",
    "\tdeltaS = np.zeros_like(imgout)\n",
    "\tdeltaE = deltaS.copy()\n",
    "\tNS = deltaS.copy()\n",
    "\tEW = deltaS.copy()\n",
    "\tgS = np.ones_like(imgout)\n",
    "\tgE = gS.copy()\n",
    "\n",
    "\t# create the plot figure, if requested\n",
    "\tif ploton:\n",
    "\t\timport pylab as pl\n",
    "\t\tfrom time import sleep\n",
    "\n",
    "\t\tfig = pl.figure(figsize=(20,5.5),num=\"Anisotropic diffusion\")\n",
    "\t\tax1,ax2 = fig.add_subplot(1,2,1),fig.add_subplot(1,2,2)\n",
    "\n",
    "\t\tax1.imshow(img,interpolation='nearest')\n",
    "\t\tih = ax2.imshow(imgout,interpolation='nearest',animated=True)\n",
    "\t\tax1.set_title(\"Original image\")\n",
    "\t\tax2.set_title(\"Iteration 0\")\n",
    "\n",
    "\t\tfig.canvas.draw()\n",
    "\n",
    "\tfor ii in np.arange(1,niter):\n",
    "\n",
    "\t\t# calculate the diffs\n",
    "\t\tdeltaS[:-1,: ] = np.diff(imgout,axis=0)\n",
    "\t\tdeltaE[: ,:-1] = np.diff(imgout,axis=1)\n",
    "\n",
    "\t\tif 0<sigma:\n",
    "\t\t\tdeltaSf=flt.gaussian_filter(deltaS,sigma);\n",
    "\t\t\tdeltaEf=flt.gaussian_filter(deltaE,sigma);\n",
    "\t\telse: \n",
    "\t\t\tdeltaSf=deltaS;\n",
    "\t\t\tdeltaEf=deltaE;\n",
    "\t\t\t\n",
    "\t\t# conduction gradients (only need to compute one per dim!)\n",
    "\t\tif option == 1:\n",
    "\t\t\tgS = np.exp(-(deltaSf/kappa)**2.)/step[0]\n",
    "\t\t\tgE = np.exp(-(deltaEf/kappa)**2.)/step[1]\n",
    "\t\telif option == 2:\n",
    "\t\t\tgS = 1./(1.+(deltaSf/kappa)**2.)/step[0]\n",
    "\t\t\tgE = 1./(1.+(deltaEf/kappa)**2.)/step[1]\n",
    "\n",
    "\t\t# update matrices\n",
    "\t\tE = gE*deltaE\n",
    "\t\tS = gS*deltaS\n",
    "\n",
    "\t\t# subtract a copy that has been shifted 'North/West' by one\n",
    "\t\t# pixel. don't as questions. just do it. trust me.\n",
    "\t\tNS[:] = S\n",
    "\t\tEW[:] = E\n",
    "\t\tNS[1:,:] -= S[:-1,:]\n",
    "\t\tEW[:,1:] -= E[:,:-1]\n",
    "\n",
    "\t\t# update the image\n",
    "\t\timgout += gamma*(NS+EW)\n",
    "\n",
    "\t\tif ploton:\n",
    "\t\t\titerstring = \"Iteration %i\" %(ii+1)\n",
    "\t\t\tih.set_data(imgout)\n",
    "\t\t\tax2.set_title(iterstring)\n",
    "\t\t\tfig.canvas.draw()\n",
    "\t\t\t# sleep(0.01)\n",
    "\n",
    "\treturn imgout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19d02295-e8d6-49e0-a853-b5ada1cc3043",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anisotropic_diffusion_func(image):\n",
    "    # Split the color image into its RGB channels\n",
    "    alpha = 0.1  # Diffusion factor\n",
    "    K = 30       # Perona-Malik coefficient\n",
    "    niters = 10  # Number of iterations\n",
    "    b, g, r = cv2.split(image)\n",
    "\n",
    "    # Apply anisotropic diffusion to each channel\n",
    "    b_filtered = anisodiff(b,kappa=30)\n",
    "    g_filtered = anisodiff(g,kappa=30)\n",
    "    r_filtered = anisodiff(r,kappa=30)\n",
    "\n",
    "    # Merge the filtered channels back into a color image\n",
    "    filtered_image = cv2.merge([b_filtered, g_filtered, r_filtered])\n",
    "    return filtered_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f629b577-69a0-4ab1-9075-9cdae9d3e4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise(model, img):\n",
    "    # Read the input image\n",
    "#input_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    input_img= img.astype(np.float32)/ 255.0\n",
    "    # Process the image\n",
    "    processed_img = _process_image(input_img, model)\n",
    "\n",
    "    return processed_img\n",
    "\n",
    "def _process_image(input_img, model):\n",
    "    # Resize the input image\n",
    "    image = tf.convert_to_tensor(input_img)\n",
    "    \n",
    "    # Handle multi-stage outputs, obtain the last scale output of the last stage\n",
    "    preds = model.predict(tf.expand_dims(image, axis=0))\n",
    "    if isinstance(preds,list):\n",
    "        preds = preds[-1]\n",
    "        if isinstance(preds,list):\n",
    "            preds = preds[-1]\n",
    "    preds = np.array(preds[0], np.float32)*255.0\n",
    "    preds = (preds - np.min(preds))/(np.max(preds)- np.min(preds)) * 255\n",
    "    preds = preds.astype(np.uint8)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0263cb71-beca-4702-982d-af57a424df4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Type: underexposure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  8.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating evaluation metrics ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:27<00:00,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Type: underexposure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  6.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating evaluation metrics ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:19<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Type: underexposure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  8.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating evaluation metrics ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:17<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Type: underexposure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  9.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating evaluation metrics ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:18<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Type: overexposure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating evaluation metrics ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:16<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Type: overexposure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating evaluation metrics ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:16<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Type: overexposure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating evaluation metrics ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:19<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Type: overexposure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  9.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating evaluation metrics ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:16<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Type: blur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  7.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating evaluation metrics ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:16<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Type: blur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  9.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating evaluation metrics ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:18<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Type: blur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating evaluation metrics ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:16<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Type: blur\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 10.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating evaluation metrics ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing:  20%|██████████████▏                                                        | 2/10 [00:03<00:14,  1.76s/it]D:\\Pranav\\Code\\eval_metrics.py:63: RuntimeWarning: divide by zero encountered in divide\n",
      "  outCT += np.log(1 + np.mean(x1 / x2))\n",
      "processing: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:16<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Type: contrast\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  5.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating evaluation metrics ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:20<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Type: contrast\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  5.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating evaluation metrics ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:25<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Type: contrast\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating evaluation metrics ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:26<00:00,  2.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Type: contrast\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  7.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating evaluation metrics ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:26<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Type: dirtylens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating evaluation metrics ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:26<00:00,  2.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Type: dirtylens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  5.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating evaluation metrics ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:27<00:00,  2.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Type: dirtylens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating evaluation metrics ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:30<00:00,  3.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Type: dirtylens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating evaluation metrics ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:24<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Type: dirtylens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating evaluation metrics ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:29<00:00,  2.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Type: dirtylens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  5.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating evaluation metrics ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing:  70%|█████████████████████████████████████████████████▋                     | 7/10 [00:18<00:06,  2.24s/it]D:\\Pranav\\Code\\eval_metrics.py:63: RuntimeWarning: divide by zero encountered in divide\n",
      "  outCT += np.log(1 + np.mean(x1 / x2))\n",
      "processing: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:26<00:00,  2.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Type: dirtylens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  5.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating evaluation metrics ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:27<00:00,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Type: dirtylens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  5.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating evaluation metrics ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:26<00:00,  2.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Type: salt&pepper\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating evaluation metrics ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:51<00:00,  5.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Type: salt&pepper\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating evaluation metrics ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:33<00:00,  3.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Type: salt&pepper\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:03<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating evaluation metrics ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:29<00:00,  2.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Type: salt&pepper\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:03<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating evaluation metrics ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:23<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Type: resize\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  8.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating evaluation metrics ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:25<00:00,  2.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Type: resize\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  6.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating evaluation metrics ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:25<00:00,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Type: resize\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  8.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating evaluation metrics ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:27<00:00,  2.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Type: resize\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating evaluation metrics ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:30<00:00,  3.05s/it]\n"
     ]
    }
   ],
   "source": [
    "for noise_type in noise_types:\n",
    "    noisy_data = []\n",
    "    agc_corrected_data = []\n",
    "    max_corrected_data = []\n",
    "    ad_corrected_data = []\n",
    "    \n",
    "    noise_name = noise_type.split('-')[0]\n",
    "    print(\"Noise Type: \" + noise_name)\n",
    "    \n",
    "    if \"exposure\" in noise_type.lower() or \"contrast\" in noise_type.lower() or \"shadow\" in noise_type.lower() or \"dark\" in noise_type.lower():\n",
    "        model = enhancement_model\n",
    "    elif \"blur\" in noise_type.lower():\n",
    "        model = deblurring_model\n",
    "    elif \"rain\" in noise_type.lower() or \"snow\" in noise_type.lower():\n",
    "        model = deraining_model\n",
    "    elif \"haz\" in noise_type.lower():\n",
    "        model = dehazing_model\n",
    "    else:\n",
    "        model = denoising_model\n",
    "    \n",
    "    path = 'D:/Pranav/Data/CURE-OR/input/' + noise_type\n",
    "    save_dir = 'D:/Pranav/Data/CURE-OR/output/' + noise_type\n",
    "    noisy_files = sorted([f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and not f.startswith('.')])\n",
    "    selected_noisy_files = [noisy_files[i] for i in idx]\n",
    "    for i in tqdm(selected_noisy_files):\n",
    "        img = cv2.imread(path + '/' + i, 1)  # Change 0 to 1 for color images\n",
    "        img = cv2.resize(img, (SIZE, SIZE))\n",
    "        if not os.path.exists(save_dir + '/Gamma Correction'):\n",
    "            os.makedirs(save_dir + '/Gamma Correction')\n",
    "            os.makedirs(save_dir + '/Maxim')\n",
    "            os.makedirs(save_dir + '/Anisotropic Diffusion')\n",
    "\n",
    "        op_agc = IAGC.adaptive_gamma_correction(img)\n",
    "        op_max = denoise(model, img)\n",
    "        op_ad = anisotropic_diffusion_func(img)\n",
    "        cv2.imwrite(save_dir + '/Gamma Correction/' + i + '.png',op_agc)\n",
    "        cv2.imwrite(save_dir + '/Maxim/' + i + '.png',op_max)\n",
    "        cv2.imwrite(save_dir + '/Anisotropic Diffusion/' + i + '.png',op_ad)\n",
    "        noisy_data.append(np.array(img))\n",
    "        agc_corrected_data.append(np.array(op_agc))\n",
    "        max_corrected_data.append(np.array(op_max))\n",
    "        ad_corrected_data.append(np.array(op_ad))\n",
    "        \n",
    "    metrics, mean_values_initial, mean_values_after_agc, mean_values_after_max, mean_values_after_ad = calc_eval_metrics(clean_data, noisy_data, agc_corrected_data, max_corrected_data, ad_corrected_data)\n",
    "\n",
    "    df_agc = df_agc._append({'Noise Type': noise_type, 'PSNR': f'{mean_values_initial[0][0]}/{mean_values_after_agc[0][0]}', \n",
    "                                'SSIM': f'{mean_values_initial[1][0]}/{mean_values_after_agc[1][0]}', \n",
    "                                'CW-SSIM': f'{mean_values_initial[2][0]}/{mean_values_after_agc[2][0]}', \n",
    "                                'UNIQUE': f'{mean_values_initial[3][0]}/{mean_values_after_agc[3][0]}',\n",
    "                                'MSUNIQUE': f'{mean_values_initial[4][0]}/{mean_values_after_agc[4][0]}',\n",
    "                                'SUMMER': f'{mean_values_initial[5][0]}/{mean_values_after_agc[5][0]}',\n",
    "                                'CSV': f'{mean_values_initial[6][0]}/{mean_values_after_agc[6][0]}'}, ignore_index=True)\n",
    "    \n",
    "    df_max = df_max._append({'Noise Type': noise_type, 'PSNR': f'{mean_values_initial[0][0]}/{mean_values_after_max[0][0]}', \n",
    "                                'SSIM': f'{mean_values_initial[1][0]}/{mean_values_after_max[1][0]}', \n",
    "                                'CW-SSIM': f'{mean_values_initial[2][0]}/{mean_values_after_max[2][0]}', \n",
    "                                'UNIQUE': f'{mean_values_initial[3][0]}/{mean_values_after_max[3][0]}',\n",
    "                                'MSUNIQUE': f'{mean_values_initial[4][0]}/{mean_values_after_max[4][0]}',\n",
    "                                'SUMMER': f'{mean_values_initial[5][0]}/{mean_values_after_max[5][0]}',\n",
    "                                'CSV': f'{mean_values_initial[6][0]}/{mean_values_after_max[6][0]}'}, ignore_index=True)\n",
    "    \n",
    "    df_ad = df_ad._append({'Noise Type': noise_type, 'PSNR': f'{mean_values_initial[0][0]}/{mean_values_after_ad[0][0]}', \n",
    "                                'SSIM': f'{mean_values_initial[1][0]}/{mean_values_after_ad[1][0]}', \n",
    "                                'CW-SSIM': f'{mean_values_initial[2][0]}/{mean_values_after_ad[2][0]}', \n",
    "                                'UNIQUE': f'{mean_values_initial[3][0]}/{mean_values_after_ad[3][0]}',\n",
    "                                'MSUNIQUE': f'{mean_values_initial[4][0]}/{mean_values_after_ad[4][0]}',\n",
    "                                'SUMMER': f'{mean_values_initial[5][0]}/{mean_values_after_ad[5][0]}',\n",
    "                                'CSV': f'{mean_values_initial[6][0]}/{mean_values_after_ad[6][0]}'}, ignore_index=True)\n",
    "    \n",
    "    \n",
    "    path = \"D:/Pranav/Results/CURE-OR\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    \n",
    "    # Save the table to a file\n",
    "    filename = path+'/'+ \"AGC.csv\"\n",
    "    df_agc.to_csv(filename, index=False)\n",
    "    \n",
    "    filename = path+'/'+ \"MAXIM.csv\"\n",
    "    df_max.to_csv(filename, index=False)\n",
    "    \n",
    "    filename = path+'/'+ \"AD.csv\"\n",
    "    df_ad.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "691188cb-968b-4f7c-bcdb-dd2f9ebff38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b803199a-fb20-4df2-a8cb-57745647c6eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
