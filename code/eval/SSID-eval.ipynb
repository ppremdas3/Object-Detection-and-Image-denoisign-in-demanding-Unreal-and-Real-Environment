{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3591b2f0-a437-4642-8d96-0718af65b8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Pranav\\dip\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import maxim_pred as maxim\n",
    "import IAGC\n",
    "import cv2\n",
    "import numpy as np\n",
    "import eval_metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import matlab.engine\n",
    "import random\n",
    "from medpy.filter.smoothing import anisotropic_diffusion\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f31deed-6b69-4ded-895d-53ef749b9bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_eval_metrics(clean_data, noisy_data, agc_corrected_data, max_corrected_data, ad_corrected_data):\n",
    "    pre_psnr = []\n",
    "    post_psnr = []\n",
    "    pre_ssim = []\n",
    "    post_ssim = []\n",
    "    pre_cwssim = []\n",
    "    post_cwssim = []\n",
    "    pre_unique = []\n",
    "    post_unique = []\n",
    "    pre_msunique = []\n",
    "    post_msunique = []\n",
    "    pre_summer = []\n",
    "    post_summer = []\n",
    "    pre_csv = []\n",
    "    post_csv = []\n",
    "\n",
    "    post_psnr1 = []\n",
    "    post_ssim1 = []\n",
    "    post_cwssim1 = []\n",
    "    post_unique1 = []\n",
    "    post_msunique1 = []\n",
    "    post_summer1 = []\n",
    "    post_csv1 = []\n",
    "\n",
    "    post_psnr2 = []\n",
    "    post_ssim2 = []\n",
    "    post_cwssim2 = []\n",
    "    post_unique2 = []\n",
    "    post_msunique2 = []\n",
    "    post_summer2 = []\n",
    "    post_csv2 = []\n",
    "\n",
    "\n",
    "    print('Calculating evaluation metrics ...')\n",
    "    for i in tqdm(range(len(clean_data)), desc='processing'):\n",
    "        cimg = clean_data[i]\n",
    "        nimg = noisy_data[i]\n",
    "        y_agc = agc_corrected_data[i]\n",
    "        y_max = max_corrected_data[i]\n",
    "        y_ad = ad_corrected_data[i]\n",
    "    \n",
    "\n",
    "        m_cimg = matlab.double(cimg.tolist())\n",
    "        m_nimg = matlab.double(nimg.tolist())\n",
    "        m_y_agc = matlab.double(y_agc.tolist())\n",
    "        m_y_max = matlab.double(y_max.tolist())\n",
    "        m_y_ad = matlab.double(y_ad.tolist())\n",
    "\n",
    "        # Convert BGR to RGB\n",
    "        cimg = cv2.cvtColor(cimg, cv2.COLOR_BGR2RGB)\n",
    "        nimg = cv2.cvtColor(nimg, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        \n",
    "        pre_psnr.append(eval_metrics.PSNR(cimg, nimg))\n",
    "        pre_ssim.append(eval_metrics.calculate_ssim(cimg, nimg))\n",
    "        pre_cwssim.append(eval_metrics.calculate_cwssim(cimg, nimg))\n",
    "        pre_summer.append(eval_metrics.calculate_summer(cimg, nimg))\n",
    "        unique_val = eng.mslUNIQUE(m_cimg, m_nimg)\n",
    "        pre_unique.append(np.array(unique_val))\n",
    "        msunique_val = eng.mslMSUNIQUE(m_cimg, m_nimg)\n",
    "        pre_msunique.append(np.array(msunique_val))\n",
    "        csv_val = eng.csv(m_cimg, m_nimg)\n",
    "        pre_csv.append(np.array(csv_val))\n",
    "\n",
    "        post_psnr.append(eval_metrics.PSNR(cimg, y_agc))\n",
    "        post_ssim.append(eval_metrics.calculate_ssim(cimg, y_agc))\n",
    "        post_cwssim.append(eval_metrics.calculate_cwssim(cimg, y_agc))\n",
    "        post_summer.append(eval_metrics.calculate_summer(cimg, y_agc))\n",
    "        unique_val = eng.mslUNIQUE(m_cimg, m_y_agc)\n",
    "        post_unique.append(np.array(unique_val))\n",
    "        msunique_val = eng.mslMSUNIQUE(m_cimg, m_y_agc)\n",
    "        post_msunique.append(np.array(msunique_val))\n",
    "        csv_val = eng.csv(m_cimg, m_y_agc)\n",
    "        post_csv.append(np.array(csv_val))\n",
    "\n",
    "        post_psnr1.append(eval_metrics.PSNR(cimg, y_max))\n",
    "        post_ssim1.append(eval_metrics.calculate_ssim(cimg, y_max))\n",
    "        post_cwssim1.append(eval_metrics.calculate_cwssim(cimg, y_max))\n",
    "        post_summer1.append(eval_metrics.calculate_summer(cimg, y_max))\n",
    "        unique_val = eng.mslUNIQUE(m_cimg, m_y_max)\n",
    "        post_unique1.append(np.array(unique_val))\n",
    "        msunique_val = eng.mslMSUNIQUE(m_cimg, m_y_max)\n",
    "        post_msunique1.append(np.array(msunique_val))\n",
    "        csv_val = eng.csv(m_cimg, m_y_max)\n",
    "        post_csv1.append(np.array(csv_val))\n",
    "\n",
    "        post_psnr2.append(eval_metrics.PSNR(cimg, y_ad))\n",
    "        post_ssim2.append(eval_metrics.calculate_ssim(cimg, y_ad))\n",
    "        post_cwssim2.append(eval_metrics.calculate_cwssim(cimg, y_ad))\n",
    "        post_summer2.append(eval_metrics.calculate_summer(cimg, y_ad))\n",
    "        unique_val = eng.mslUNIQUE(m_cimg, m_y_ad)\n",
    "        post_unique2.append(np.array(unique_val))\n",
    "        msunique_val = eng.mslMSUNIQUE(m_cimg, m_y_ad)\n",
    "        post_msunique2.append(np.array(msunique_val))\n",
    "        csv_val = eng.csv(m_cimg, m_y_ad)\n",
    "        post_csv2.append(np.array(csv_val))\n",
    "\n",
    "    metrics = ['PSNR', 'SSIM', 'CWSSIM', 'UNIQUE', 'MSUNIQUE', 'SUMMER', 'CSV']\n",
    "    mean_values_initial = []\n",
    "    for i, lst in enumerate([pre_psnr, pre_ssim, pre_cwssim, pre_unique, pre_msunique, pre_summer, pre_csv]):\n",
    "        mean_value = np.mean(lst)\n",
    "        mean_values_initial.append([f\"{mean_value:.3f}\"])\n",
    "\n",
    "    # Display the mean values after adding 10 to the first element\n",
    "    mean_values_after_agc = []\n",
    "    for i, lst in enumerate([post_psnr, post_ssim, post_cwssim, post_unique, post_msunique, post_summer, post_csv]):\n",
    "        mean_value = np.mean(lst)\n",
    "        mean_values_after_agc.append([f\"{mean_value:.3f}\"])\n",
    "\n",
    "    # Display the mean values after adding 10 to the first element\n",
    "    mean_values_after_max = []\n",
    "    for i, lst in enumerate([post_psnr1, post_ssim1, post_cwssim1, post_unique1, post_msunique1, post_summer1, post_csv1]):\n",
    "        mean_value = np.mean(lst)\n",
    "        mean_values_after_max.append([f\"{mean_value:.3f}\"])\n",
    "\n",
    "    # Display the mean values after adding 10 to the first element\n",
    "    mean_values_after_ad = []\n",
    "    for i, lst in enumerate([post_psnr2, post_ssim2, post_cwssim2, post_unique2, post_msunique2, post_summer2, post_csv2]):\n",
    "        mean_value = np.mean(lst)\n",
    "        mean_values_after_ad.append([f\"{mean_value:.3f}\"])\n",
    "\n",
    "    return metrics, mean_values_initial, mean_values_after_agc, mean_values_after_max, mean_values_after_ad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c53e6161-53a5-452a-959b-d801ffd11893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading clean data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:03<00:00,  2.96it/s]\n"
     ]
    }
   ],
   "source": [
    "# cure-TSD evaluation\n",
    "SIZE = 256\n",
    "path = 'D:/Pranav/Data/SIDD/input'\n",
    "clean_files = sorted([f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and not f.startswith('.')])\n",
    "idx = random.sample(range(len(clean_files)), 10)\n",
    "selected_clean_files = [clean_files[i] for i in idx]\n",
    "clean_data = []\n",
    "print('Loading clean data ...')\n",
    "for i in tqdm(selected_clean_files):\n",
    "    img = cv2.imread(path + '/' + i, 1)  # Change 0 to 1 for color images\n",
    "    img = cv2.resize(img, (SIZE, SIZE))\n",
    "    clean_data.append(np.array(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73ed67e7-f835-4cd2-bde0-967ad5c74286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Pranav\\dip\\Lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:107: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Pranav\\dip\\Lib\\site-packages\\keras\\src\\engine\\functional.py:156: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Pranav\\dip\\Lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:178: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Pranav\\dip\\Lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:178: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "denoising_model = tf.keras.models.load_model('D:/Pranav/Code/maxim-tf-main/models/Denoising')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40007026-460f-473a-abd6-4fa1ee93fd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agc = pd.DataFrame(columns=['Noise Type', 'PSNR', 'SSIM', 'CW-SSIM', 'UNIQUE', 'MSUNIQUE', 'SUMMER', 'CSV'])\n",
    "df_max = pd.DataFrame(columns=['Noise Type', 'PSNR', 'SSIM', 'CW-SSIM', 'UNIQUE', 'MSUNIQUE', 'SUMMER', 'CSV'])\n",
    "df_ad = pd.DataFrame(columns=['Noise Type', 'PSNR', 'SSIM', 'CW-SSIM', 'UNIQUE', 'MSUNIQUE', 'SUMMER', 'CSV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ec9497c-3351-437d-a729-bfc3c436ba84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as io\n",
    "import skimage.filters as flt\n",
    "%matplotlib inline\n",
    "# since we can't use imports\n",
    "import numpy as np\n",
    "import scipy.ndimage.filters as flt\n",
    "import warnings\n",
    "\n",
    "def anisodiff(img,niter=10,kappa=50,gamma=0.1,step=(1.,1.),sigma=0, option=1,ploton=False):\n",
    "\t# really want\n",
    "\tif img.ndim == 3:\n",
    "\t\twarnings.warn(\"Only grayscale images allowed, converting to 2D matrix\")\n",
    "\t\timg = img.mean(2)\n",
    "\n",
    "\t# initialize output array\n",
    "\timg = img.astype('float32')\n",
    "\timgout = img.copy()\n",
    "\n",
    "\t# initialize some internal variables\n",
    "\tdeltaS = np.zeros_like(imgout)\n",
    "\tdeltaE = deltaS.copy()\n",
    "\tNS = deltaS.copy()\n",
    "\tEW = deltaS.copy()\n",
    "\tgS = np.ones_like(imgout)\n",
    "\tgE = gS.copy()\n",
    "\n",
    "\t# create the plot figure, if requested\n",
    "\tif ploton:\n",
    "\t\timport pylab as pl\n",
    "\t\tfrom time import sleep\n",
    "\n",
    "\t\tfig = pl.figure(figsize=(20,5.5),num=\"Anisotropic diffusion\")\n",
    "\t\tax1,ax2 = fig.add_subplot(1,2,1),fig.add_subplot(1,2,2)\n",
    "\n",
    "\t\tax1.imshow(img,interpolation='nearest')\n",
    "\t\tih = ax2.imshow(imgout,interpolation='nearest',animated=True)\n",
    "\t\tax1.set_title(\"Original image\")\n",
    "\t\tax2.set_title(\"Iteration 0\")\n",
    "\n",
    "\t\tfig.canvas.draw()\n",
    "\n",
    "\tfor ii in np.arange(1,niter):\n",
    "\n",
    "\t\t# calculate the diffs\n",
    "\t\tdeltaS[:-1,: ] = np.diff(imgout,axis=0)\n",
    "\t\tdeltaE[: ,:-1] = np.diff(imgout,axis=1)\n",
    "\n",
    "\t\tif 0<sigma:\n",
    "\t\t\tdeltaSf=flt.gaussian_filter(deltaS,sigma);\n",
    "\t\t\tdeltaEf=flt.gaussian_filter(deltaE,sigma);\n",
    "\t\telse: \n",
    "\t\t\tdeltaSf=deltaS;\n",
    "\t\t\tdeltaEf=deltaE;\n",
    "\t\t\t\n",
    "\t\t# conduction gradients (only need to compute one per dim!)\n",
    "\t\tif option == 1:\n",
    "\t\t\tgS = np.exp(-(deltaSf/kappa)**2.)/step[0]\n",
    "\t\t\tgE = np.exp(-(deltaEf/kappa)**2.)/step[1]\n",
    "\t\telif option == 2:\n",
    "\t\t\tgS = 1./(1.+(deltaSf/kappa)**2.)/step[0]\n",
    "\t\t\tgE = 1./(1.+(deltaEf/kappa)**2.)/step[1]\n",
    "\n",
    "\t\t# update matrices\n",
    "\t\tE = gE*deltaE\n",
    "\t\tS = gS*deltaS\n",
    "\n",
    "\t\t# subtract a copy that has been shifted 'North/West' by one\n",
    "\t\t# pixel. don't as questions. just do it. trust me.\n",
    "\t\tNS[:] = S\n",
    "\t\tEW[:] = E\n",
    "\t\tNS[1:,:] -= S[:-1,:]\n",
    "\t\tEW[:,1:] -= E[:,:-1]\n",
    "\n",
    "\t\t# update the image\n",
    "\t\timgout += gamma*(NS+EW)\n",
    "\n",
    "\t\tif ploton:\n",
    "\t\t\titerstring = \"Iteration %i\" %(ii+1)\n",
    "\t\t\tih.set_data(imgout)\n",
    "\t\t\tax2.set_title(iterstring)\n",
    "\t\t\tfig.canvas.draw()\n",
    "\t\t\t# sleep(0.01)\n",
    "\n",
    "\treturn imgout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd096962-450d-4d82-aa9d-7ada622a8d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anisotropic_diffusion_func(image):\n",
    "    # Split the color image into its RGB channels\n",
    "    alpha = 0.1  # Diffusion factor\n",
    "    K = 30       # Perona-Malik coefficient\n",
    "    niters = 10  # Number of iterations\n",
    "    b, g, r = cv2.split(image)\n",
    "\n",
    "    # Apply anisotropic diffusion to each channel\n",
    "    b_filtered = anisodiff(b,kappa=30)\n",
    "    g_filtered = anisodiff(g,kappa=30)\n",
    "    r_filtered = anisodiff(r,kappa=30)\n",
    "\n",
    "    # Merge the filtered channels back into a color image\n",
    "    filtered_image = cv2.merge([b_filtered, g_filtered, r_filtered])\n",
    "    return filtered_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c96b7b36-b5ac-4d25-b187-289a84f6f57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise(model, img):\n",
    "    # Read the input image\n",
    "#input_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    input_img= img.astype(np.float32)/ 255.0\n",
    "    # Process the image\n",
    "    processed_img = _process_image(input_img, model)\n",
    "\n",
    "    return processed_img\n",
    "\n",
    "def _process_image(input_img, model):\n",
    "    # Resize the input image\n",
    "    image = tf.convert_to_tensor(input_img)\n",
    "    \n",
    "    # Handle multi-stage outputs, obtain the last scale output of the last stage\n",
    "    preds = model.predict(tf.expand_dims(image, axis=0))\n",
    "    if isinstance(preds,list):\n",
    "        preds = preds[-1]\n",
    "        if isinstance(preds,list):\n",
    "            preds = preds[-1]\n",
    "    preds = np.array(preds[0], np.float32)*255.0\n",
    "    preds = (preds - np.min(preds))/(np.max(preds)- np.min(preds)) * 255\n",
    "    preds = preds.astype(np.uint8)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a70c545d-6eed-495d-af5a-e16c04716117",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Underexposed Image\n",
      "1/1 [==============================] - 10s 10s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 1/10 [00:15<02:18, 15.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Underexposed Image\n",
      "1/1 [==============================] - 9s 9s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 2/10 [00:24<01:35, 11.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Underexposed Image\n",
      "1/1 [==============================] - 8s 8s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 3/10 [00:34<01:15, 10.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Underexposed Image\n",
      "1/1 [==============================] - 8s 8s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 4/10 [00:42<00:59,  9.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Underexposed Image\n",
      "1/1 [==============================] - 7s 7s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [00:51<00:46,  9.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Underexposed Image\n",
      "1/1 [==============================] - 7s 7s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [00:59<00:35,  8.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Underexposed Image\n",
      "1/1 [==============================] - 8s 8s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [01:08<00:26,  8.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Underexposed Image\n",
      "1/1 [==============================] - 7s 7s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [01:16<00:17,  8.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Underexposed Image\n",
      "1/1 [==============================] - 7s 7s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [01:24<00:08,  8.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Underexposed Image\n",
      "1/1 [==============================] - 7s 7s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:32<00:00,  9.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating evaluation metrics ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|██████████████████████████████████████████████████████████████████████| 10/10 [00:39<00:00,  3.91s/it]\n"
     ]
    }
   ],
   "source": [
    "eng = matlab.engine.start_matlab()\n",
    "noise_type = 'Noise'\n",
    "noisy_data = []\n",
    "agc_corrected_data = []\n",
    "max_corrected_data = []\n",
    "ad_corrected_data = []\n",
    "    \n",
    "model = denoising_model\n",
    "    \n",
    "path = 'D:/Pranav/Data/SIDD/noisy'\n",
    "save_dir = 'D:/Pranav/Data/SIDD/output'\n",
    "noisy_files = sorted([f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and not f.startswith('.')])\n",
    "selected_noisy_files = [noisy_files[i] for i in idx]\n",
    "for i in tqdm(selected_noisy_files):\n",
    "    img = cv2.imread(path + '/' + i, 1)  # Change 0 to 1 for color images\n",
    "    img = cv2.resize(img, (SIZE, SIZE))\n",
    "    if not os.path.exists(save_dir + '/Gamma Correction'):\n",
    "        os.makedirs(save_dir + '/Gamma Correction')\n",
    "        os.makedirs(save_dir + '/Maxim')\n",
    "        os.makedirs(save_dir + '/Anisotropic Diffusion')\n",
    "\n",
    "    op_agc = IAGC.adaptive_gamma_correction(img)\n",
    "    op_max = denoise(model, img)\n",
    "    op_ad = anisotropic_diffusion_func(img)\n",
    "    cv2.imwrite(save_dir + '/Gamma Correction/' + i + '.png',op_agc)\n",
    "    cv2.imwrite(save_dir + '/Maxim/' + i + '.png',op_max)\n",
    "    cv2.imwrite(save_dir + '/Anisotropic Diffusion/' + i + '.png',op_ad)\n",
    "    noisy_data.append(np.array(img))\n",
    "    agc_corrected_data.append(np.array(op_agc))\n",
    "    max_corrected_data.append(np.array(op_max))\n",
    "    ad_corrected_data.append(np.array(op_ad))\n",
    "        \n",
    "metrics, mean_values_initial, mean_values_after_agc, mean_values_after_max, mean_values_after_ad = calc_eval_metrics(clean_data, noisy_data, agc_corrected_data, max_corrected_data, ad_corrected_data)\n",
    "\n",
    "df_agc = df_agc._append({'Noise Type': noise_type, 'PSNR': f'{mean_values_initial[0][0]}/{mean_values_after_agc[0][0]}', \n",
    "                            'SSIM': f'{mean_values_initial[1][0]}/{mean_values_after_agc[1][0]}', \n",
    "                            'CW-SSIM': f'{mean_values_initial[2][0]}/{mean_values_after_agc[2][0]}', \n",
    "                            'UNIQUE': f'{mean_values_initial[3][0]}/{mean_values_after_agc[3][0]}',\n",
    "                            'MSUNIQUE': f'{mean_values_initial[4][0]}/{mean_values_after_agc[4][0]}',\n",
    "                            'SUMMER': f'{mean_values_initial[5][0]}/{mean_values_after_agc[5][0]}',\n",
    "                            'CSV': f'{mean_values_initial[6][0]}/{mean_values_after_agc[6][0]}'}, ignore_index=True)\n",
    "    \n",
    "df_max = df_max._append({'Noise Type': noise_type, 'PSNR': f'{mean_values_initial[0][0]}/{mean_values_after_max[0][0]}', \n",
    "                            'SSIM': f'{mean_values_initial[1][0]}/{mean_values_after_max[1][0]}', \n",
    "                            'CW-SSIM': f'{mean_values_initial[2][0]}/{mean_values_after_max[2][0]}', \n",
    "                            'UNIQUE': f'{mean_values_initial[3][0]}/{mean_values_after_max[3][0]}',\n",
    "                            'MSUNIQUE': f'{mean_values_initial[4][0]}/{mean_values_after_max[4][0]}',\n",
    "                            'SUMMER': f'{mean_values_initial[5][0]}/{mean_values_after_max[5][0]}',\n",
    "                            'CSV': f'{mean_values_initial[6][0]}/{mean_values_after_max[6][0]}'}, ignore_index=True)\n",
    "    \n",
    "df_ad = df_ad._append({'Noise Type': noise_type, 'PSNR': f'{mean_values_initial[0][0]}/{mean_values_after_ad[0][0]}', \n",
    "                            'SSIM': f'{mean_values_initial[1][0]}/{mean_values_after_ad[1][0]}', \n",
    "                            'CW-SSIM': f'{mean_values_initial[2][0]}/{mean_values_after_ad[2][0]}', \n",
    "                            'UNIQUE': f'{mean_values_initial[3][0]}/{mean_values_after_ad[3][0]}',\n",
    "                            'MSUNIQUE': f'{mean_values_initial[4][0]}/{mean_values_after_ad[4][0]}',\n",
    "                            'SUMMER': f'{mean_values_initial[5][0]}/{mean_values_after_ad[5][0]}',\n",
    "                            'CSV': f'{mean_values_initial[6][0]}/{mean_values_after_ad[6][0]}'}, ignore_index=True)\n",
    "    \n",
    "    \n",
    "path = \"D:/Pranav/Results/SIDD\"\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "    \n",
    "# Save the table to a file\n",
    "filename = path+'/'+ \"AGC.csv\"\n",
    "df_agc.to_csv(filename, index=False)\n",
    "    \n",
    "filename = path+'/'+ \"MAXIM.csv\"\n",
    "df_max.to_csv(filename, index=False)\n",
    "    \n",
    "filename = path+'/'+ \"AD.csv\"\n",
    "df_ad.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39020b5c-923f-4a6b-90b5-dbeb521f2fa7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
