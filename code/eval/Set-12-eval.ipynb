{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16bfac27-bb38-432f-b60e-441426792ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Pranav\\dip\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import maxim_pred as maxim\n",
    "import IAGC\n",
    "import cv2\n",
    "import numpy as np\n",
    "import eval_metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import matlab.engine\n",
    "import random\n",
    "from medpy.filter.smoothing import anisotropic_diffusion\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbb41ac5-44bf-4b03-956b-1694cd41cab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_eval_metrics(clean_data, noisy_data, agc_corrected_data, max_corrected_data, ad_corrected_data):\n",
    "    pre_psnr = []\n",
    "    post_psnr = []\n",
    "    pre_ssim = []\n",
    "    post_ssim = []\n",
    "    pre_cwssim = []\n",
    "    post_cwssim = []\n",
    "    pre_unique = []\n",
    "    post_unique = []\n",
    "    pre_msunique = []\n",
    "    post_msunique = []\n",
    "    pre_summer = []\n",
    "    post_summer = []\n",
    "    pre_csv = []\n",
    "    post_csv = []\n",
    "\n",
    "    post_psnr1 = []\n",
    "    post_ssim1 = []\n",
    "    post_cwssim1 = []\n",
    "    post_unique1 = []\n",
    "    post_msunique1 = []\n",
    "    post_summer1 = []\n",
    "    post_csv1 = []\n",
    "\n",
    "    post_psnr2 = []\n",
    "    post_ssim2 = []\n",
    "    post_cwssim2 = []\n",
    "    post_unique2 = []\n",
    "    post_msunique2 = []\n",
    "    post_summer2 = []\n",
    "    post_csv2 = []\n",
    "\n",
    "\n",
    "    print('Calculating evaluation metrics ...')\n",
    "    for i in tqdm(range(len(clean_data)), desc='processing'):\n",
    "        cimg = clean_data[i]\n",
    "        nimg = noisy_data[i]\n",
    "        y_agc = agc_corrected_data[i]\n",
    "        y_max = max_corrected_data[i]\n",
    "        y_ad = ad_corrected_data[i]\n",
    "    \n",
    "\n",
    "        m_cimg = matlab.double(cimg.tolist())\n",
    "        m_nimg = matlab.double(nimg.tolist())\n",
    "        m_y_agc = matlab.double(y_agc.tolist())\n",
    "        m_y_max = matlab.double(y_max.tolist())\n",
    "        m_y_ad = matlab.double(y_ad.tolist())\n",
    "\n",
    "        # Convert BGR to RGB\n",
    "        cimg = cv2.cvtColor(cimg, cv2.COLOR_BGR2RGB)\n",
    "        nimg = cv2.cvtColor(nimg, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        \n",
    "        pre_psnr.append(eval_metrics.PSNR(cimg, nimg))\n",
    "        pre_ssim.append(eval_metrics.calculate_ssim(cimg, nimg))\n",
    "        pre_cwssim.append(eval_metrics.calculate_cwssim(cimg, nimg))\n",
    "        pre_summer.append(eval_metrics.calculate_summer(cimg, nimg))\n",
    "        unique_val = eng.mslUNIQUE(m_cimg, m_nimg)\n",
    "        pre_unique.append(np.array(unique_val))\n",
    "        msunique_val = eng.mslMSUNIQUE(m_cimg, m_nimg)\n",
    "        pre_msunique.append(np.array(msunique_val))\n",
    "        csv_val = eng.csv(m_cimg, m_nimg)\n",
    "        pre_csv.append(np.array(csv_val))\n",
    "\n",
    "        post_psnr.append(eval_metrics.PSNR(cimg, y_agc))\n",
    "        post_ssim.append(eval_metrics.calculate_ssim(cimg, y_agc))\n",
    "        post_cwssim.append(eval_metrics.calculate_cwssim(cimg, y_agc))\n",
    "        post_summer.append(eval_metrics.calculate_summer(cimg, y_agc))\n",
    "        unique_val = eng.mslUNIQUE(m_cimg, m_y_agc)\n",
    "        post_unique.append(np.array(unique_val))\n",
    "        msunique_val = eng.mslMSUNIQUE(m_cimg, m_y_agc)\n",
    "        post_msunique.append(np.array(msunique_val))\n",
    "        csv_val = eng.csv(m_cimg, m_y_agc)\n",
    "        post_csv.append(np.array(csv_val))\n",
    "\n",
    "        post_psnr1.append(eval_metrics.PSNR(cimg, y_max))\n",
    "        post_ssim1.append(eval_metrics.calculate_ssim(cimg, y_max))\n",
    "        post_cwssim1.append(eval_metrics.calculate_cwssim(cimg, y_max))\n",
    "        post_summer1.append(eval_metrics.calculate_summer(cimg, y_max))\n",
    "        unique_val = eng.mslUNIQUE(m_cimg, m_y_max)\n",
    "        post_unique1.append(np.array(unique_val))\n",
    "        msunique_val = eng.mslMSUNIQUE(m_cimg, m_y_max)\n",
    "        post_msunique1.append(np.array(msunique_val))\n",
    "        csv_val = eng.csv(m_cimg, m_y_max)\n",
    "        post_csv1.append(np.array(csv_val))\n",
    "\n",
    "        post_psnr2.append(eval_metrics.PSNR(cimg, y_ad))\n",
    "        post_ssim2.append(eval_metrics.calculate_ssim(cimg, y_ad))\n",
    "        post_cwssim2.append(eval_metrics.calculate_cwssim(cimg, y_ad))\n",
    "        post_summer2.append(eval_metrics.calculate_summer(cimg, y_ad))\n",
    "        unique_val = eng.mslUNIQUE(m_cimg, m_y_ad)\n",
    "        post_unique2.append(np.array(unique_val))\n",
    "        msunique_val = eng.mslMSUNIQUE(m_cimg, m_y_ad)\n",
    "        post_msunique2.append(np.array(msunique_val))\n",
    "        csv_val = eng.csv(m_cimg, m_y_ad)\n",
    "        post_csv2.append(np.array(csv_val))\n",
    "\n",
    "    metrics = ['PSNR', 'SSIM', 'CWSSIM', 'UNIQUE', 'MSUNIQUE', 'SUMMER', 'CSV']\n",
    "    mean_values_initial = []\n",
    "    for i, lst in enumerate([pre_psnr, pre_ssim, pre_cwssim, pre_unique, pre_msunique, pre_summer, pre_csv]):\n",
    "        mean_value = np.mean(lst)\n",
    "        mean_values_initial.append([f\"{mean_value:.3f}\"])\n",
    "\n",
    "    # Display the mean values after adding 10 to the first element\n",
    "    mean_values_after_agc = []\n",
    "    for i, lst in enumerate([post_psnr, post_ssim, post_cwssim, post_unique, post_msunique, post_summer, post_csv]):\n",
    "        mean_value = np.mean(lst)\n",
    "        mean_values_after_agc.append([f\"{mean_value:.3f}\"])\n",
    "\n",
    "    # Display the mean values after adding 10 to the first element\n",
    "    mean_values_after_max = []\n",
    "    for i, lst in enumerate([post_psnr1, post_ssim1, post_cwssim1, post_unique1, post_msunique1, post_summer1, post_csv1]):\n",
    "        mean_value = np.mean(lst)\n",
    "        mean_values_after_max.append([f\"{mean_value:.3f}\"])\n",
    "\n",
    "    # Display the mean values after adding 10 to the first element\n",
    "    mean_values_after_ad = []\n",
    "    for i, lst in enumerate([post_psnr2, post_ssim2, post_cwssim2, post_unique2, post_msunique2, post_summer2, post_csv2]):\n",
    "        mean_value = np.mean(lst)\n",
    "        mean_values_after_ad.append([f\"{mean_value:.3f}\"])\n",
    "\n",
    "    return metrics, mean_values_initial, mean_values_after_agc, mean_values_after_max, mean_values_after_ad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ded0545-3697-48d1-8326-08e3ff2fc85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading clean data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 16.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# cure-OR evaluation\n",
    "SIZE = 256\n",
    "path = 'D:/Pranav/Data/Set12/input/Ground-truth'\n",
    "clean_files = sorted([f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and not f.startswith('.')])\n",
    "clean_data = []\n",
    "print('Loading clean data ...')\n",
    "for i in tqdm(clean_files):\n",
    "    img = cv2.imread(path + '/' + i, 1)  # Change 0 to 1 for color images\n",
    "    img = cv2.resize(img, (SIZE, SIZE))\n",
    "    clean_data.append(np.array(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9743ec6-ac34-4bca-8001-171ffb7a16ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Noisy-1', 'Noisy-2', 'Noisy-3']\n"
     ]
    }
   ],
   "source": [
    "directory_path = 'D:/Pranav/Data/Set12/input/'\n",
    "# Get a list of folder names in the directory\n",
    "noise_types = [folder for folder in os.listdir(directory_path) if os.path.isdir(os.path.join(directory_path, folder))]\n",
    "noise_types.remove('Ground-truth')\n",
    "eng = matlab.engine.start_matlab()\n",
    "print(noise_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "180c0f47-73a3-4988-bdec-837d04bb6134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Pranav\\dip\\Lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:107: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Pranav\\dip\\Lib\\site-packages\\keras\\src\\engine\\functional.py:156: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Pranav\\dip\\Lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:178: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Pranav\\dip\\Lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:178: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "denoising_model = tf.keras.models.load_model('D:/Pranav/Code/maxim-tf-main/models/Denoising')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0f35fe9-aea9-4a3e-ae6a-8a1150bd6367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_agc = pd.DataFrame(columns=['Noise Type', 'PSNR', 'SSIM', 'CW-SSIM', 'UNIQUE', 'MSUNIQUE', 'SUMMER', 'CSV'])\n",
    "df_max = pd.DataFrame(columns=['Noise Type', 'PSNR', 'SSIM', 'CW-SSIM', 'UNIQUE', 'MSUNIQUE', 'SUMMER', 'CSV'])\n",
    "df_ad = pd.DataFrame(columns=['Noise Type', 'PSNR', 'SSIM', 'CW-SSIM', 'UNIQUE', 'MSUNIQUE', 'SUMMER', 'CSV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1634fa7c-88ef-4f51-8a7d-4a4b73a63eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as io\n",
    "import skimage.filters as flt\n",
    "%matplotlib inline\n",
    "# since we can't use imports\n",
    "import numpy as np\n",
    "import scipy.ndimage.filters as flt\n",
    "import warnings\n",
    "\n",
    "def anisodiff(img,niter=10,kappa=50,gamma=0.1,step=(1.,1.),sigma=0, option=1,ploton=False):\n",
    "\t# really want\n",
    "\tif img.ndim == 3:\n",
    "\t\twarnings.warn(\"Only grayscale images allowed, converting to 2D matrix\")\n",
    "\t\timg = img.mean(2)\n",
    "\n",
    "\t# initialize output array\n",
    "\timg = img.astype('float32')\n",
    "\timgout = img.copy()\n",
    "\n",
    "\t# initialize some internal variables\n",
    "\tdeltaS = np.zeros_like(imgout)\n",
    "\tdeltaE = deltaS.copy()\n",
    "\tNS = deltaS.copy()\n",
    "\tEW = deltaS.copy()\n",
    "\tgS = np.ones_like(imgout)\n",
    "\tgE = gS.copy()\n",
    "\n",
    "\t# create the plot figure, if requested\n",
    "\tif ploton:\n",
    "\t\timport pylab as pl\n",
    "\t\tfrom time import sleep\n",
    "\n",
    "\t\tfig = pl.figure(figsize=(20,5.5),num=\"Anisotropic diffusion\")\n",
    "\t\tax1,ax2 = fig.add_subplot(1,2,1),fig.add_subplot(1,2,2)\n",
    "\n",
    "\t\tax1.imshow(img,interpolation='nearest')\n",
    "\t\tih = ax2.imshow(imgout,interpolation='nearest',animated=True)\n",
    "\t\tax1.set_title(\"Original image\")\n",
    "\t\tax2.set_title(\"Iteration 0\")\n",
    "\n",
    "\t\tfig.canvas.draw()\n",
    "\n",
    "\tfor ii in np.arange(1,niter):\n",
    "\n",
    "\t\t# calculate the diffs\n",
    "\t\tdeltaS[:-1,: ] = np.diff(imgout,axis=0)\n",
    "\t\tdeltaE[: ,:-1] = np.diff(imgout,axis=1)\n",
    "\n",
    "\t\tif 0<sigma:\n",
    "\t\t\tdeltaSf=flt.gaussian_filter(deltaS,sigma);\n",
    "\t\t\tdeltaEf=flt.gaussian_filter(deltaE,sigma);\n",
    "\t\telse: \n",
    "\t\t\tdeltaSf=deltaS;\n",
    "\t\t\tdeltaEf=deltaE;\n",
    "\t\t\t\n",
    "\t\t# conduction gradients (only need to compute one per dim!)\n",
    "\t\tif option == 1:\n",
    "\t\t\tgS = np.exp(-(deltaSf/kappa)**2.)/step[0]\n",
    "\t\t\tgE = np.exp(-(deltaEf/kappa)**2.)/step[1]\n",
    "\t\telif option == 2:\n",
    "\t\t\tgS = 1./(1.+(deltaSf/kappa)**2.)/step[0]\n",
    "\t\t\tgE = 1./(1.+(deltaEf/kappa)**2.)/step[1]\n",
    "\n",
    "\t\t# update matrices\n",
    "\t\tE = gE*deltaE\n",
    "\t\tS = gS*deltaS\n",
    "\n",
    "\t\t# subtract a copy that has been shifted 'North/West' by one\n",
    "\t\t# pixel. don't as questions. just do it. trust me.\n",
    "\t\tNS[:] = S\n",
    "\t\tEW[:] = E\n",
    "\t\tNS[1:,:] -= S[:-1,:]\n",
    "\t\tEW[:,1:] -= E[:,:-1]\n",
    "\n",
    "\t\t# update the image\n",
    "\t\timgout += gamma*(NS+EW)\n",
    "\n",
    "\t\tif ploton:\n",
    "\t\t\titerstring = \"Iteration %i\" %(ii+1)\n",
    "\t\t\tih.set_data(imgout)\n",
    "\t\t\tax2.set_title(iterstring)\n",
    "\t\t\tfig.canvas.draw()\n",
    "\t\t\t# sleep(0.01)\n",
    "\n",
    "\treturn imgout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9d5b28f-e30b-4c3b-bbf7-aac43f21f335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anisotropic_diffusion_func(image):\n",
    "    # Split the color image into its RGB channels\n",
    "    alpha = 0.1  # Diffusion factor\n",
    "    K = 30       # Perona-Malik coefficient\n",
    "    niters = 10  # Number of iterations\n",
    "    b, g, r = cv2.split(image)\n",
    "\n",
    "    # Apply anisotropic diffusion to each channel\n",
    "    b_filtered = anisodiff(b,kappa=30)\n",
    "    g_filtered = anisodiff(g,kappa=30)\n",
    "    r_filtered = anisodiff(r,kappa=30)\n",
    "\n",
    "    # Merge the filtered channels back into a color image\n",
    "    filtered_image = cv2.merge([b_filtered, g_filtered, r_filtered])\n",
    "    return filtered_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebfa4f6f-45e6-4eb6-a290-e9abb14065a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise(model, img):\n",
    "    # Read the input image\n",
    "#input_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    input_img= img.astype(np.float32)/ 255.0\n",
    "    # Process the image\n",
    "    processed_img = _process_image(input_img, model)\n",
    "\n",
    "    return processed_img\n",
    "\n",
    "def _process_image(input_img, model):\n",
    "    # Resize the input image\n",
    "    image = tf.convert_to_tensor(input_img)\n",
    "    \n",
    "    # Handle multi-stage outputs, obtain the last scale output of the last stage\n",
    "    preds = model.predict(tf.expand_dims(image, axis=0))\n",
    "    if isinstance(preds,list):\n",
    "        preds = preds[-1]\n",
    "        if isinstance(preds,list):\n",
    "            preds = preds[-1]\n",
    "    preds = np.array(preds[0], np.float32)*255.0\n",
    "    preds = (preds - np.min(preds))/(np.max(preds)- np.min(preds)) * 255\n",
    "    preds = preds.astype(np.uint8)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be9dc592-2a8e-4277-aa95-1143161ad863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Type: Noisy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:01<00:00,  6.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating evaluation metrics ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|██████████████████████████████████████████████████████████████████████| 12/12 [00:23<00:00,  2.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Type: Noisy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:01<00:00,  8.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating evaluation metrics ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|██████████████████████████████████████████████████████████████████████| 12/12 [00:20<00:00,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise Type: Noisy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:01<00:00,  6.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating evaluation metrics ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing: 100%|██████████████████████████████████████████████████████████████████████| 12/12 [00:20<00:00,  1.70s/it]\n"
     ]
    }
   ],
   "source": [
    "for noise_type in noise_types:\n",
    "    noisy_data = []\n",
    "    agc_corrected_data = []\n",
    "    max_corrected_data = []\n",
    "    ad_corrected_data = []\n",
    "    \n",
    "    noise_name = noise_type.split('-')[0]\n",
    "    print(\"Noise Type: \" + noise_name)\n",
    "    \n",
    "    if \"exposure\" in noise_type.lower() or \"contrast\" in noise_type.lower() or \"shadow\" in noise_type.lower() or \"dark\" in noise_type.lower():\n",
    "        model = enhancement_model\n",
    "    elif \"blur\" in noise_type.lower():\n",
    "        model = deblurring_model\n",
    "    elif \"rain\" in noise_type.lower() or \"snow\" in noise_type.lower():\n",
    "        model = deraining_model\n",
    "    elif \"haz\" in noise_type.lower():\n",
    "        model = dehazing_model\n",
    "    else:\n",
    "        model = denoising_model\n",
    "    \n",
    "    path = 'D:/Pranav/Data/Set12/input/' + noise_type\n",
    "    save_dir = 'D:/Pranav/Data/Set12/output/' + noise_type\n",
    "    noisy_files = sorted([f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and not f.startswith('.')])\n",
    "    for i in tqdm(noisy_files):\n",
    "        img = cv2.imread(path + '/' + i, 1)  # Change 0 to 1 for color images\n",
    "        img = cv2.resize(img, (SIZE, SIZE))\n",
    "        if not os.path.exists(save_dir + '/Gamma Correction'):\n",
    "            os.makedirs(save_dir + '/Gamma Correction')\n",
    "            os.makedirs(save_dir + '/Maxim')\n",
    "            os.makedirs(save_dir + '/Anisotropic Diffusion')\n",
    "\n",
    "        op_agc = IAGC.adaptive_gamma_correction(img)\n",
    "        op_max = denoise(model, img)\n",
    "        op_ad = anisotropic_diffusion_func(img)\n",
    "        cv2.imwrite(save_dir + '/Gamma Correction/' + i + '.png',op_agc)\n",
    "        cv2.imwrite(save_dir + '/Maxim/' + i + '.png',op_max)\n",
    "        cv2.imwrite(save_dir + '/Anisotropic Diffusion/' + i + '.png',op_ad)\n",
    "        noisy_data.append(np.array(img))\n",
    "        agc_corrected_data.append(np.array(op_agc))\n",
    "        max_corrected_data.append(np.array(op_max))\n",
    "        ad_corrected_data.append(np.array(op_ad))\n",
    "        \n",
    "    metrics, mean_values_initial, mean_values_after_agc, mean_values_after_max, mean_values_after_ad = calc_eval_metrics(clean_data, noisy_data, agc_corrected_data, max_corrected_data, ad_corrected_data)\n",
    "\n",
    "    df_agc = df_agc._append({'Noise Type': noise_type, 'PSNR': f'{mean_values_initial[0][0]}/{mean_values_after_agc[0][0]}', \n",
    "                                'SSIM': f'{mean_values_initial[1][0]}/{mean_values_after_agc[1][0]}', \n",
    "                                'CW-SSIM': f'{mean_values_initial[2][0]}/{mean_values_after_agc[2][0]}', \n",
    "                                'UNIQUE': f'{mean_values_initial[3][0]}/{mean_values_after_agc[3][0]}',\n",
    "                                'MSUNIQUE': f'{mean_values_initial[4][0]}/{mean_values_after_agc[4][0]}',\n",
    "                                'SUMMER': f'{mean_values_initial[5][0]}/{mean_values_after_agc[5][0]}',\n",
    "                                'CSV': f'{mean_values_initial[6][0]}/{mean_values_after_agc[6][0]}'}, ignore_index=True)\n",
    "    \n",
    "    df_max = df_max._append({'Noise Type': noise_type, 'PSNR': f'{mean_values_initial[0][0]}/{mean_values_after_max[0][0]}', \n",
    "                                'SSIM': f'{mean_values_initial[1][0]}/{mean_values_after_max[1][0]}', \n",
    "                                'CW-SSIM': f'{mean_values_initial[2][0]}/{mean_values_after_max[2][0]}', \n",
    "                                'UNIQUE': f'{mean_values_initial[3][0]}/{mean_values_after_max[3][0]}',\n",
    "                                'MSUNIQUE': f'{mean_values_initial[4][0]}/{mean_values_after_max[4][0]}',\n",
    "                                'SUMMER': f'{mean_values_initial[5][0]}/{mean_values_after_max[5][0]}',\n",
    "                                'CSV': f'{mean_values_initial[6][0]}/{mean_values_after_max[6][0]}'}, ignore_index=True)\n",
    "    \n",
    "    df_ad = df_ad._append({'Noise Type': noise_type, 'PSNR': f'{mean_values_initial[0][0]}/{mean_values_after_ad[0][0]}', \n",
    "                                'SSIM': f'{mean_values_initial[1][0]}/{mean_values_after_ad[1][0]}', \n",
    "                                'CW-SSIM': f'{mean_values_initial[2][0]}/{mean_values_after_ad[2][0]}', \n",
    "                                'UNIQUE': f'{mean_values_initial[3][0]}/{mean_values_after_ad[3][0]}',\n",
    "                                'MSUNIQUE': f'{mean_values_initial[4][0]}/{mean_values_after_ad[4][0]}',\n",
    "                                'SUMMER': f'{mean_values_initial[5][0]}/{mean_values_after_ad[5][0]}',\n",
    "                                'CSV': f'{mean_values_initial[6][0]}/{mean_values_after_ad[6][0]}'}, ignore_index=True)\n",
    "    \n",
    "    \n",
    "    path = \"D:/Pranav/Results/Set12\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    \n",
    "    # Save the table to a file\n",
    "    filename = path+'/'+ \"AGC.csv\"\n",
    "    df_agc.to_csv(filename, index=False)\n",
    "    \n",
    "    filename = path+'/'+ \"MAXIM.csv\"\n",
    "    df_max.to_csv(filename, index=False)\n",
    "    \n",
    "    filename = path+'/'+ \"AD.csv\"\n",
    "    df_ad.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72e56351-7129-446a-9d57-31a86ac74238",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58baaef5-303a-4581-916b-1d91d2b3aa67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
